
---
title: "Metro Melbourne COVID-19 2023 survey; Census 2016 & 2021 residential relocation"
runningheader: "Metro Melbourne COVID-19 2023 survey; Census 2016 & 2021 residential relocation" # only for pdf output
subtitle: "Data analysis" # only for html output
author: "Dr James Reynolds, Public Transport Research Group (PTRG), Monash University"
date: "`r Sys.Date()`"
output:
  tufte::tufte_html: 
    margin_references: false
    citation_package: natbib
  tufte::tufte_handout:
    citation_package: natbib
    latex_engine: xelatex
  tufte::tufte_book:
    citation_package: natbib
    latex_engine: xelatex
bibliography: skeleton.bib
link-citations: yes
---

```{r setup, include=FALSE}
library(tufte)
# invalidate cache when the tufte version changes
knitr::opts_chunk$set(cache.extra = packageVersion('tufte'))
options(htmltools.dir.version = FALSE)
```


# 1.0 Introduction
As part of the work program for the upcoming Metro Melbourne COVID-19 2023 (second) survey PTRG is comparing the usual place of residence results from the 2016 and 2021 Australian census. The analysis includes looking at Metro Melbourne as a whole, and also the inner, middle and outer regions individually^[With those regions being as defined in the 2020 (first) survey.], as well as the Peri-Urban Area and Rest of Victoria regions that will be used for the forthcoming Regional Victoria COVID-19 2023 survey. 

This work note summarises the analysis and findings. The next section discusses the datasets retrieved from the Australian Bureau of Statistics (ABS) Table Builder. Section 3 shows the regions used in the 2020 (first) survey and this analysis. Section 4 presents the analysis results.


# 2.0 Data 
Eight datasets were extracted as Comma-Separated Values (CSV) files using the ABS Table Builder online system. These were the results for the questions about usual place of residence 1 year ago and 5 years ago^[Specifically the Place of Usual Residence one year ago (PUR1P) and Place of Usual Residence five years ago (PUR5P) variables.  Details are avaiable at https://www.abs.gov.au/census/guide-census-data/census-dictionary/2021/variables-topic/location/place-usual-residence-one-year-ago-pur1p], with data retrieved for the 2016 and 2021 censuses. Separate tables were extracted for respondents who answered that their previous place of residence was within a specific Victorian LGA, and for those whose previous place of residence was in another state or territory. Examples from the data tables are shown below in Tables 1 and 2^[Some minor edits were made directly to the CSV files prior to importation into R. This includes fixing the LGA name fields, which were inconsistent. The 2016 version also showed the type of LGA, (Shire, Regional City or City) as letters (S, RC, C) in brackets. The 2021 CSV files were updated to adopt the 2016 approach.]. 

```{r loadsurveydata, echo=FALSE, warning = FALSE, message = FALSE, include = TRUE} 
#Load datasets
library(readr)
X2016_1yr_ago_State <- read_csv("01 data/2016_1yr_ago_State.csv", skip = 8)
X2016_1yr_ago_Vic_LGA <- read_csv("01 data/2016_1yr_ago_Vic_LGA.csv", skip = 8)
X2016_5yr_ago_State <- read_csv("01 data/2016_5yr_ago_State.csv", skip = 8)
X2016_5yr_ago_Vic_LGA <- read_csv("01 data/2016_5yr_ago_Vic_LGA.csv", skip = 8)
X2021_1yr_ago_State <- read_csv("01 data/2021_1yr_ago_State.csv", skip = 9)
X2021_1yr_ago_Vic_LGA <- read_csv("01 data/2021_1yr_ago_Vic_LGA.csv", skip = 9)
X2021_5yr_ago_State <- read_csv("01 data/2021_5yr_ago_State.csv", skip = 9)
X2021_5yr_ago_Vic_LGA <- read_csv("01 data/2021_5yr_ago_Vic_LGA.csv", skip = 9)



#delete empty first rows from each table
X2016_1yr_ago_State <- X2016_1yr_ago_State[-1,]
X2016_1yr_ago_Vic_LGA <- X2016_1yr_ago_Vic_LGA[-1,]
X2016_5yr_ago_State <- X2016_5yr_ago_State[-1,]
X2016_5yr_ago_Vic_LGA <- X2016_5yr_ago_Vic_LGA[-1,]
X2021_1yr_ago_State <- X2021_1yr_ago_State[-1,]
X2021_1yr_ago_Vic_LGA <- X2021_1yr_ago_Vic_LGA[-1,]
X2021_5yr_ago_State <- X2021_5yr_ago_State[-1,]
X2021_5yr_ago_Vic_LGA <- X2021_5yr_ago_Vic_LGA[-1,]

#delete empty last column from each table
#delete total column from each table
#also delete Not Stated, and Not Applicable; from State tables
#also delete: Capital City Undefined (Greater Melbourne),	Unincorporated Vic,	No Usual Address (Vic.),	Migratory - Offshore - Shipping (Vic.), and	State Undefined (Vic.); from LGA tables
X2016_1yr_ago_State <- X2016_1yr_ago_State[,1:(ncol(X2016_1yr_ago_State)-4)]
X2016_1yr_ago_Vic_LGA <- X2016_1yr_ago_Vic_LGA[,1:(ncol(X2016_1yr_ago_Vic_LGA)-7)]
X2016_5yr_ago_State <- X2016_5yr_ago_State[,1:(ncol(X2016_5yr_ago_State)-4)]
X2016_5yr_ago_Vic_LGA <- X2016_5yr_ago_Vic_LGA[,1:(ncol(X2016_5yr_ago_Vic_LGA)-7)]
X2021_1yr_ago_State <- X2021_1yr_ago_State[,1:(ncol(X2021_1yr_ago_State)-3)]
X2021_1yr_ago_Vic_LGA <- X2021_1yr_ago_Vic_LGA[,1:(ncol(X2021_1yr_ago_Vic_LGA)-6)]
X2021_5yr_ago_State <- X2021_5yr_ago_State[,1:(ncol(X2021_5yr_ago_State)-3)]
X2021_5yr_ago_Vic_LGA <- X2021_5yr_ago_Vic_LGA[,1:(ncol(X2021_5yr_ago_Vic_LGA)-6)]

#delete last 3 to 4 rows from each table, as they contain ABS notes etc. 
#Also remove total row, 
#Also remove Unincorporated Vic, No usual address (Vic.) and 	Migratory - Offshore - Shipping (Vic.) rows as these are small and special cases that we do not need to include in this analysis 
X2016_1yr_ago_State <- head(X2016_1yr_ago_State,-8)
X2016_1yr_ago_Vic_LGA <- head(X2016_1yr_ago_Vic_LGA,-8)
X2016_5yr_ago_State <- head(X2016_5yr_ago_State,-8)
X2016_5yr_ago_Vic_LGA <- head(X2016_5yr_ago_Vic_LGA,-8)
X2021_1yr_ago_State <- head(X2021_1yr_ago_State,-11)
X2021_1yr_ago_Vic_LGA <- head(X2021_1yr_ago_Vic_LGA,-11)
X2021_5yr_ago_State <- head(X2021_5yr_ago_State,-11)
X2021_5yr_ago_Vic_LGA <- head(X2021_5yr_ago_Vic_LGA,-11)

#Convert second column to numeric, as it is a character for some reason
X2016_1yr_ago_State$`New South Wales` <- as.numeric(X2016_1yr_ago_State$`New South Wales`)
X2016_1yr_ago_Vic_LGA$`Alpine (S)` <- as.numeric(X2016_1yr_ago_Vic_LGA$`Alpine (S)`)
X2016_5yr_ago_State$`New South Wales` <- as.numeric(X2016_5yr_ago_State$`New South Wales`)
X2016_5yr_ago_Vic_LGA$`Alpine (S)` <- as.numeric(X2016_5yr_ago_Vic_LGA$`Alpine (S)`)
X2021_1yr_ago_State$`New South Wales` <- as.numeric(X2021_1yr_ago_State$`New South Wales`)
X2021_1yr_ago_Vic_LGA$`Alpine (S)` <- as.numeric(X2021_1yr_ago_Vic_LGA$`Alpine (S)`)
X2021_5yr_ago_State$`New South Wales` <- as.numeric(X2021_5yr_ago_State$`New South Wales`)
X2021_5yr_ago_Vic_LGA$`Alpine (S)` <- as.numeric(X2021_5yr_ago_Vic_LGA$`Alpine (S)`)

#change name of first column in all dataframes to LGA
df.list <- list(X2016_1yr_ago_State, X2016_1yr_ago_Vic_LGA, X2016_5yr_ago_State, X2016_5yr_ago_Vic_LGA, X2021_1yr_ago_State, X2021_1yr_ago_Vic_LGA, X2021_5yr_ago_State, X2021_5yr_ago_Vic_LGA)
res <- lapply(df.list, function(x) {colnames(x)[1] = "LGA"; x})
names(res) <- c("X2016_1yr_ago_State", "X2016_1yr_ago_Vic_LGA", "X2016_5yr_ago_State", "X2016_5yr_ago_Vic_LGA", "X2021_1yr_ago_State", "X2021_1yr_ago_Vic_LGA", "X2021_5yr_ago_State", "X2021_5yr_ago_Vic_LGA")
invisible(list2env(res,envir=.GlobalEnv))


knitr::kable(
  head(X2016_1yr_ago_State), format.args = list(big.mark = ",", scientific = FALSE), align = "lrrrrrrrrrr", caption = 'Table 1: 2016 census, State/Territory of Usual Residence one year ago (PUR1P), results by LGA for Victoria, first 6 results')

#knitr::kable(
#  head(rowSums(X2016_1yr_ago_State[,2:ncol(X2016_1yr_ago_State)])), format.args = list(big.mark = ",", scientific = FALSE), align = "lrrrrr", caption = 'Table 1a: 2016 census, State/Territory of Usual Residence one year ago (PUR1P), results by LGA for Victoria, row sums, first 6 results')
####This was just to check that the rows added up correctly. 

knitr::kable(
  head(X2016_1yr_ago_Vic_LGA[,1:11]), format.args = list(big.mark = ",", scientific = FALSE), align = "lrrrrrrrrrr", caption = 'Table 2: 2016 census, LGA of Usual Residence one year ago (PUR1P), results by LGA for Victoria, first 6 results')


#knitr::kable(
#  head(rowSums(X2016_1yr_ago_Vic_LGA[,2:ncol(X2016_1yr_ago_Vic_LGA)])), format.args = list(big.mark = ",", scientific = FALSE), align = "lrrrrr", caption = 'Table 2a: 2016 census, LGA of Usual Residence one year ago (PUR1P), results by LGA for Victoria, row sums, first 6 results')
####This was just to check that the rows added up correctly.  In general, the sum here (10,743 for Apline) is close to matching the Victoria entry in Table 1 (10,802). Minor differences expect due to randomisation of ABS tables, and removal of Melbourne not specified, missing etc. 


```

The Place of Usual Residence (PURP1P, PUR5P) variables from the ABS datasets includes people who did not move in the values shown for each LGA and State/Territory.  Therefore the datasets for the Usual address one year ago indicator (UAI1P) and Usual address five years ago indicator (UAI5P)^[See details at https://www.abs.gov.au/census/guide-census-data/census-dictionary/2021/variables-topic/location/usual-address-one-year-ago-indicator-uai1p. As an example, the 10,359 people from Alpine Shire in 2016 whose place of usual residence was (also) within Alpine Shire one year prior to the 2016 census (from Table 2) consist of 9,711 who had not moved house (see Table 3) and 648 who had moved house, but to somewhere else within the Alpine Shire (as 10,359-9,711-648.] were also extracted using the ABS Table Builder tool^{Again, some minor edits were made directly to the CSV files prior to importation into R]. An example of the UAI1P data table is shown below in Table 3. 


```{r load_place_indicator, echo=FALSE, warning = FALSE, message = FALSE, include = TRUE} 
#Load datasets
library(readr)
X2016_usual_address_1yr_ago_indicator <- read_csv("01 data/2016_usual_address_1yr_ago_indicator.csv", skip = 8)
X2016_usual_address_5yr_ago_indicator <- read_csv("01 data/2016_usual_address_5yr_ago_indicator.csv", skip = 8)
X2021_usual_address_1yr_ago_indicator <- read_csv("01 data/2021_usual_address_1yr_ago_indicator.csv", skip = 9)
X2021_usual_address_5yr_ago_indicator <- read_csv("01 data/2021_usual_address_5yr_ago_indicator.csv", skip = 9)



#delete empty first rows from each table
X2016_usual_address_1yr_ago_indicator <- X2016_usual_address_1yr_ago_indicator[-1,]
X2016_usual_address_5yr_ago_indicator <- X2016_usual_address_5yr_ago_indicator[-1,]
X2021_usual_address_1yr_ago_indicator <- X2021_usual_address_1yr_ago_indicator[-1,]
X2021_usual_address_5yr_ago_indicator <- X2021_usual_address_5yr_ago_indicator[-1,]

#delete empty last column from 2016 table
#delete total column from each table
X2016_usual_address_1yr_ago_indicator <- X2016_usual_address_1yr_ago_indicator[,1:(ncol(X2016_usual_address_1yr_ago_indicator)-2)]
X2016_usual_address_5yr_ago_indicator <- X2016_usual_address_5yr_ago_indicator[,1:(ncol(X2016_usual_address_5yr_ago_indicator)-2)]
X2021_usual_address_1yr_ago_indicator <- X2021_usual_address_1yr_ago_indicator[,1:(ncol(X2021_usual_address_1yr_ago_indicator)-1)]
X2021_usual_address_5yr_ago_indicator <- X2021_usual_address_5yr_ago_indicator[,1:(ncol(X2021_usual_address_5yr_ago_indicator)-1)]


#delete last 3 to 4 rows from each table, as they contain ABS notes etc. 
#Also remove total row, 
#Also remove Unincorporated Vic, No usual address (Vic.) and 	Migratory - Offshore - Shipping (Vic.) rows as these are small and special cases that we do not need to include in this analysis 
X2016_usual_address_1yr_ago_indicator <- head(X2016_usual_address_1yr_ago_indicator,-8)
X2016_usual_address_5yr_ago_indicator <- head(X2016_usual_address_5yr_ago_indicator,-8)
X2021_usual_address_1yr_ago_indicator <- head(X2021_usual_address_1yr_ago_indicator,-11)
X2021_usual_address_5yr_ago_indicator <- head(X2021_usual_address_5yr_ago_indicator,-11)

#Convert second column to numeric, as it is a character for some reason
X2016_usual_address_1yr_ago_indicator$`Same as in 2016` <- as.numeric(X2016_usual_address_1yr_ago_indicator$`Same as in 2016`)
X2016_usual_address_5yr_ago_indicator$`Same as in 2016` <- as.numeric(X2016_usual_address_5yr_ago_indicator$`Same as in 2016`)
X2021_usual_address_1yr_ago_indicator$`Same as in 2021` <- as.numeric(X2021_usual_address_1yr_ago_indicator$`Same as in 2021`)
X2021_usual_address_5yr_ago_indicator$`Same as in 2021` <- as.numeric(X2021_usual_address_5yr_ago_indicator$`Same as in 2021`)

#change name of first column in all dataframes to LGA
df.list <- list(X2016_usual_address_1yr_ago_indicator, X2016_usual_address_5yr_ago_indicator, X2021_usual_address_1yr_ago_indicator, X2021_usual_address_5yr_ago_indicator)
df.list <- lapply(df.list, function(x) {colnames(x)[1] = "LGA"; x})
names(df.list) <- c("X2016_usual_address_1yr_ago_indicator", "X2016_usual_address_5yr_ago_indicator", "X2021_usual_address_1yr_ago_indicator", "X2021_usual_address_5yr_ago_indicator")
invisible(list2env(df.list,envir=.GlobalEnv))


knitr::kable(
  head(X2016_usual_address_1yr_ago_indicator), format.args = list(big.mark = ",", scientific = FALSE), align = "lrrrrr", caption = 'Table 3: 2016 census, Usual Address one year ago Indicator (UAI1P), results by LGA for Victoria, first 6 results')

#knitr::kable(
#  head(rowSums(X2016_usual_address_1yr_ago_indicator[,2:ncol(X2016_usual_address_1yr_ago_indicator)])), format.args = list(big.mark = ",", scientific = FALSE), align = "lrrrrr", caption = 'Table 3a: 2016 census, Usual Address one year ago Indicator (UAI1P), results by LGA for Victoria, row sums, first 6 results')
###Just checking totals again.  All good as Apline total (12,331) minus the Not Stated and Not applicables (1,107+94=1,201) matches the Table 1a total

```

Combining the tables (PUR1P by State and by LGA, and UAI1P) gives a single table for each census and time period^[2016 and 2021 census; 1 year ago and 5 years ago]. Table 4 shows an example of the combined tables. 

```{r same_as_in_to_seperate_column, echo=FALSE, warning=FALSE, message=FALSE, include = TRUE} 

#Move State dataframes  in list
df.State.list <- list(X2016_1yr_ago_State, X2016_5yr_ago_State, X2021_1yr_ago_State,  X2021_5yr_ago_State)
names(df.State.list) <- c("X2016_1yr_ago_State", "X2016_5yr_ago_State", "X2021_1yr_ago_State", "X2021_5yr_ago_State")
#remove Victoria column from State dataframes list
df.State.list <- lapply(df.State.list, function(x) {x[-c(3)]})
#return State dataframes out of list
invisible(list2env(df.State.list,envir=.GlobalEnv))


#Move LGA dataframes  in list
df.LGA.list <- list(X2016_1yr_ago_Vic_LGA, X2016_5yr_ago_Vic_LGA, X2021_1yr_ago_Vic_LGA,  X2021_5yr_ago_Vic_LGA)
names(df.LGA.list) <- c("X2016_1yr_ago_Vic_LGA", "X2016_5yr_ago_Vic_LGA", "X2021_1yr_ago_Vic_LGA", "X2021_5yr_ago_Vic_LGA")


#Move usual address indicator dataframes  in list
df.usual_address.list <- list(X2016_usual_address_1yr_ago_indicator, X2016_usual_address_5yr_ago_indicator, X2021_usual_address_1yr_ago_indicator,  X2021_usual_address_5yr_ago_indicator)
names(df.LGA.list) <- c("X2016_usual_address_1yr_ago_indicator", "X2016_usual_address_5yr_ago_indicator", "X2021_usual_address_1yr_ago_indicator", "X2021_usual_address_5yr_ago_indicator")






#merge dataframes 2016 1 yr ago
X2016_combined_1yr_ago <- merge(X2016_usual_address_1yr_ago_indicator, X2016_1yr_ago_Vic_LGA, by.x = "LGA", by.y = "LGA")
X2016_combined_1yr_ago <- merge(X2016_combined_1yr_ago, X2016_1yr_ago_State, by.x = "LGA", by.y = "LGA")
#merge dataframes 2016 5 yr ago
X2016_combined_5yr_ago <- merge(X2016_usual_address_5yr_ago_indicator, X2016_5yr_ago_Vic_LGA, by.x = "LGA", by.y = "LGA")
X2016_combined_5yr_ago <- merge(X2016_combined_5yr_ago, X2016_5yr_ago_State, by.x = "LGA", by.y = "LGA")

#merge dataframes 2021 1 yr ago
X2021_combined_1yr_ago <- merge(X2021_usual_address_1yr_ago_indicator, X2021_1yr_ago_Vic_LGA, by.x = "LGA", by.y = "LGA")
X2021_combined_1yr_ago <- merge(X2021_combined_1yr_ago, X2021_1yr_ago_State, by.x = "LGA", by.y = "LGA")
#merge dataframes 2021 5 yr ago
X2021_combined_5yr_ago <- merge(X2021_usual_address_5yr_ago_indicator, X2021_5yr_ago_Vic_LGA, by.x = "LGA", by.y = "LGA")
X2021_combined_5yr_ago <- merge(X2021_combined_5yr_ago, X2021_5yr_ago_State, by.x = "LGA", by.y = "LGA")


#remove duplicated last (Overseas) columns from each dataframe
X2016_combined_1yr_ago <- X2016_combined_1yr_ago[,1:(ncol(X2016_combined_1yr_ago)-1)]
X2016_combined_5yr_ago <- X2016_combined_5yr_ago[,1:(ncol(X2016_combined_5yr_ago)-1)]
X2021_combined_1yr_ago <- X2021_combined_1yr_ago[,1:(ncol(X2021_combined_1yr_ago)-1)]
X2021_combined_5yr_ago <- X2021_combined_5yr_ago[,1:(ncol(X2021_combined_5yr_ago)-1)]


#write function to subtract the "Same as in YYYY" column from the relevant LGA column for each (LGA) row
function.subtract_same_as_in_YYYY_column <- function(df){
for (i in 1:nrow(df)){
    LGA_name <- df[i,1]
    same_location_number <- df[i,2]
    column_number_of_LGA_name <- which(colnames(df)==LGA_name)
df[i,column_number_of_LGA_name] <- df[i,column_number_of_LGA_name]-same_location_number
  }
return(df)}

#Move combined dataframes  into list
df.combined_by_LGA.list <- list(X2016_combined_1yr_ago, X2016_combined_5yr_ago, X2021_combined_1yr_ago,  X2021_combined_5yr_ago)
names(df.combined_by_LGA.list) <- c("X2016_combined_1yr_ago", "X2016_combined_5yr_ago", "X2021_combined_1yr_ago", "X2021_combined_5yr_ago")

#run function.subtract_same_as_in_YYYY_column on dataframes in the combined list
df.combined_by_LGA.list <- lapply(df.combined_by_LGA.list, function(x) {function.subtract_same_as_in_YYYY_column(x)})
names(df.combined_by_LGA.list) <- c("X2016_combined_1yr_ago", "X2016_combined_5yr_ago", "X2021_combined_1yr_ago", "X2021_combined_5yr_ago")

#remove Elsewhere in Australia column
df.combined_by_LGA.list <- lapply(df.combined_by_LGA.list, function(x){cbind(x[1:2],x[4:93])
  })



#push results of list back out to global environment
invisible(list2env(df.combined_by_LGA.list,envir=.GlobalEnv))

library(janitor)
knitr::kable(
  head(X2016_combined_1yr_ago[,1:8]), format.args = list(big.mark = ",", scientific = FALSE), align = "lrrrrrrrr", caption = 'Table 4: 2016 census, place of usual residence 1 year ago combined table,first 6 results for first 8 columns')


#knitr::kable(
#  head(rowSums(X2016_combined_1yr_ago[,2:ncol(X2016_combined_1yr_ago)])), format.args = list(big.mark = ",", scientific = FALSE), align = "lrrrrr", caption = 'Table 4a: 2016 census, place of usual residence 1 year ago combined table, first 6 results for first 8 columns')
###Just checking totals again.  All good as Apline total (12,256) matches (plus minus the randomisation issues) the Table 3a total of 12,331)




```
  
# 3.0 Regions
Inner, middle and outer regions were defined in the 2020 Melbourne COVID-19 survey, as shown in Table 5. The additional zones of Peri-Urban Area and Rest of Victoria have been defined in the work to date for the forthcoming Regional Victoria COVID-19 survey, and Table 5 also shows allocation of LGAs to those zones as well^[Note that the Peri-Urban Area and Rest of Victoria zones have actually been defined using the Statistical Area 3 (SA3) boundaries. These are slightly different to LGA boundaries, so LGAs have been assigned to one of the Peri-Urban Area and Rest of Victoria regions by inspection.]. 

```{r loadregions, echo=FALSE, warning=FALSE, message=FALSE, include = TRUE} 
#Load dataset
library(readr)
region <- read_csv("01 data/region.csv")

knitr::kable(head(region, n=15), caption = 'Table 5: Victorian LGAs by region, first 15 entries')
```

# 4.0 Results 
The raw data from the ABS table builder (Table 4) and the allocation of LGAs to each region (Table 5) have been combined. This results in tables of usual address 1 or 5 years ago, by region. Results are summarised in Tables 6-9. ^[Note, the 'not stated' and 'not applicable' fields have been dropped.].  


```{r by_region_inner_middle_etc, echo=FALSE, warning=FALSE, message=FALSE, include = TRUE} 
#This section of code creates a list of dataframes with the complete details by region (inner, middle, outer, peri-urban, rest of vic, nsw, qld etc.)

#First join the dataframe of regions with each of the dataframes in the list of combined dataframes
df.combined_by_LGA.list <- lapply(df.combined_by_LGA.list, function(X) {merge(region, X)})
#return combined dataframes out of list
invisible(list2env(df.combined_by_LGA.list,envir=.GlobalEnv))

#Now obtain the position of inner, middle etc LGAs in the dataframes (ie row/column numbers)
LGAs_inner_position <- which(region$Region == "Inner")
LGAs_middle_position <- which(region$Region == "Middle")
LGAs_outer_position <- which(region$Region == "Outer")
LGAs_peri_urban_position <- which(region$Region == "Peri-Urban Area")
LGAs_rest_of_vic_position <- which(region$Region == "Rest of Victoria")


#Next collect all inner rows, and add them together
library(janitor)
df.inner.list <- lapply(df.combined_by_LGA.list, function(X) {
  X <- X[LGAs_inner_position,]})
df.inner.list <- lapply(df.inner.list, function(X) {
  X <- X %>% adorn_totals("row")})
df.inner.list <- lapply(df.inner.list, function(X) {
  X[[nrow(X),1]] <- "Inner"
  return(X)
  })


#Next collect all middle rows, and add them together
library(janitor)
df.middle.list <- lapply(df.combined_by_LGA.list, function(X) {
  X <- X[LGAs_middle_position,]})
df.middle.list <- lapply(df.middle.list, function(X) {
  X <- X %>% adorn_totals("row")})
df.middle.list <- lapply(df.middle.list, function(X) {
  X[[nrow(X),1]] <- "Middle"
  return(X)
  })


#Next collect all outer rows, and add them together
library(janitor)
df.outer.list <- lapply(df.combined_by_LGA.list, function(X) {
  X <- X[LGAs_outer_position,]})
df.outer.list <- lapply(df.outer.list, function(X) {
  X <- X %>% adorn_totals("row")})
df.outer.list <- lapply(df.outer.list, function(X) {
  X[[nrow(X),1]] <- "Outer"
  return(X)
  })


#Next collect all peri_urban rows, and add them together
library(janitor)
df.peri_urban.list <- lapply(df.combined_by_LGA.list, function(X) {
  X <- X[LGAs_peri_urban_position,]})
df.peri_urban.list <- lapply(df.peri_urban.list, function(X) {
  X <- X %>% adorn_totals("row")})
df.peri_urban.list <- lapply(df.peri_urban.list, function(X) {
  X[[nrow(X),1]] <- "Peri-Urban Areas"
  return(X)
  })


#Next collect all rest_of_vic rows, and add them together
library(janitor)
df.rest_of_vic.list <- lapply(df.combined_by_LGA.list, function(X) {
  X <- X[LGAs_rest_of_vic_position,]})
df.rest_of_vic.list <- lapply(df.rest_of_vic.list, function(X) {
  X <- X %>% adorn_totals("row")})
df.rest_of_vic.list <- lapply(df.rest_of_vic.list, function(X) {
  X[[nrow(X),1]] <- "Rest of Victoria"
  return(X)
  })


#Then collect the Inner, middle, outer etc totals from each list and combine into one list of dataframes
#By firest creating df.lists of just the "Total" rows from each
df.inner_total.list <- lapply(df.inner.list, tail, 1)
df.middle_total.list <- lapply(df.middle.list, tail, 1)
df.outer_total.list <- lapply(df.outer.list, tail, 1)
df.peri_urban_total.list <- lapply(df.peri_urban.list, tail, 1)
df.rest_of_vic_total.list <- lapply(df.rest_of_vic.list, tail, 1)
#Then combining them
df.combined_by_region.list <- mapply(rbind, df.inner_total.list, df.middle_total.list, df.outer_total.list, df.peri_urban_total.list, df.rest_of_vic_total.list, SIMPLIFY = FALSE)

####Next, work on combining the columns
#Next collect all inner columns, and add them together
library(janitor)
library(dplyr)
library(purrr)
df.inner_columns.list <- lapply(df.combined_by_region.list, function(X) {
  X <- X[,LGAs_inner_position+7]})
df.inner_columns.list <- lapply(df.inner_columns.list, function(X) {
  X <- X %>% adorn_totals("col")})
df.inner_columns.list <- lapply(df.inner_columns.list, rename, Inner = Total)
  
#Next collect all middle columns, and add them together
library(janitor)
library(dplyr)
library(purrr)
df.middle_columns.list <- lapply(df.combined_by_region.list, function(X) {
  X <- X[,LGAs_middle_position+7]})
df.middle_columns.list <- lapply(df.middle_columns.list, function(X) {
  X <- X %>% adorn_totals("col")})
df.middle_columns.list <- lapply(df.middle_columns.list, rename, Middle = Total)
  
#Next collect all outer columns, and add them together
library(janitor)
library(dplyr)
library(purrr)
df.outer_columns.list <- lapply(df.combined_by_region.list, function(X) {
  X <- X[,LGAs_outer_position+7]})
df.outer_columns.list <- lapply(df.outer_columns.list, function(X) {
  X <- X %>% adorn_totals("col")})
df.outer_columns.list <- lapply(df.outer_columns.list, rename, Outer = Total)
  
#Next collect all peri_urban columns, and add them together
library(janitor)
library(dplyr)
library(purrr)
df.peri_urban_columns.list <- lapply(df.combined_by_region.list, function(X) {
  X <- X[,LGAs_peri_urban_position+7]})
df.peri_urban_columns.list <- lapply(df.peri_urban_columns.list, function(X) {
  X <- X %>% adorn_totals("col")})
df.peri_urban_columns.list <- lapply(df.peri_urban_columns.list, rename, "Peri-Urban Area" = Total)
  
#Next collect all rest_of_vic columns, and add them together
library(janitor)
library(dplyr)
library(purrr)
df.rest_of_vic_columns.list <- lapply(df.combined_by_region.list, function(X) {
  X <- X[,LGAs_rest_of_vic_position+7]})
df.rest_of_vic_columns.list <- lapply(df.rest_of_vic_columns.list, function(X) {
  X <- X %>% adorn_totals("col")})
df.rest_of_vic_columns.list <- lapply(df.rest_of_vic_columns.list, rename, "Rest of Victoria" = Total)
  


#Then collect the Inner, middle, outer etc totals from each list and combine into one list of dataframes
#By first creating df.lists of just the "Total" columns from each
library(tidyverse)
df.inner_columns_total.list <- lapply(df.inner_columns.list, function(x){x %>% select(last_col())})
df.middle_columns_total.list <- lapply(df.middle_columns.list, function(x){x %>% select(last_col())})
df.outer_columns_total.list <- lapply(df.outer_columns.list, function(x){x %>% select(last_col())})
df.peri_urban_columns_total.list <- lapply(df.peri_urban_columns.list, function(x){x %>% select(last_col())})
df.rest_of_vic_columns_total.list <- lapply(df.rest_of_vic_columns.list, function(x){x %>% select(last_col())})
#Then combining them
df.combined_by_region_columns.list <- mapply(cbind, df.inner_columns_total.list, df.middle_columns_total.list, df.outer_columns_total.list, df.peri_urban_columns_total.list, df.rest_of_vic_columns_total.list, SIMPLIFY = FALSE)


#Make new list of dataframes for aggregated by region. 
#first combine dataframes
df.combined_by_region.list <- mapply(cbind, df.combined_by_region.list, df.combined_by_region_columns.list, SIMPLIFY = FALSE)

#then drop repeated columns
df.combined_by_region.list <- lapply(df.combined_by_region.list, function(x){cbind(x[1],x[3], x[94:98], x[86:93], x[4])
 })

#rename first column as Region instead of LGA
df.combined_by_region.list <- lapply(df.combined_by_region.list, rename, "Region" = "LGA")

#Add total row and column
#df.combined_by_region.list <- lapply(df.combined_by_region.list, function(X) {
# X <- X %>% adorn_totals(c("row","col"))})

#Export back to Global Environment  
names(df.combined_by_region.list) <- c("X2016_combined_1yr_ago", "X2016_combined_5yr_ago", "X2021_combined_1yr_ago", "X2021_combined_5yr_ago")
invisible(list2env(df.combined_by_region.list,envir=.GlobalEnv))


#knitr::kable(
# X2016_combined_1yr_ago %>% adorn_totals(c("row", "col")), row.names = FALSE, format.args = list(big.mark = ",", scientific = FALSE), caption = 'Table 6: 2016 census, Usual address one years ago, by region')


knitr::kable(
 X2016_combined_1yr_ago %>% adorn_totals(c("row","col")) %>% adorn_percentages() %>% adorn_pct_formatting() %>% adorn_ns(ns = format(X2016_combined_1yr_ago %>% adorn_totals(c("row","col")), big.mark=","), position = "front"), row.names = FALSE, format.args = list(big.mark = ",", scientific = FALSE), align = "lrrrrrrrrrrrrrrrr", caption = 'Table 6: 2016 census, Usual address one year ago, by region')

knitr::kable(
 X2021_combined_1yr_ago %>% adorn_totals(c("row","col")) %>% adorn_percentages() %>% adorn_pct_formatting() %>% adorn_ns(ns = format(X2021_combined_1yr_ago %>% adorn_totals(c("row","col")), big.mark=","), position = "front"), row.names = FALSE, format.args = list(big.mark = ",", scientific = FALSE), align = "lrrrrrrrrrrrrrrrr", caption = 'Table 7: 2021 census, Usual address one year ago, by region')

knitr::kable(
 X2016_combined_5yr_ago %>% adorn_totals(c("row","col")) %>% adorn_percentages() %>% adorn_pct_formatting() %>% adorn_ns(ns = format(X2016_combined_5yr_ago %>% adorn_totals(c("row","col")), big.mark=","), position = "front"), row.names = FALSE, format.args = list(big.mark = ",", scientific = FALSE), align = "lrrrrrrrrrrrrrrrr", caption = 'Table 8: 2016 census, Usual address five years ago, by region')

knitr::kable(
 X2021_combined_5yr_ago %>% adorn_totals(c("row","col")) %>% adorn_percentages() %>% adorn_pct_formatting() %>% adorn_ns(ns = format(X2021_combined_5yr_ago %>% adorn_totals(c("row","col")), big.mark=","), position = "front"), row.names = FALSE, format.args = list(big.mark = ",", scientific = FALSE), align = "lrrrrrrrrrrrrrrrr", caption = 'Table 9: 2021 census, Usual address five years ago, by region')

```


Tables 6, 7, 8 and 9 have a large amount of data, which makes comparison difficult. Hence, the following sections examine various components of the usual address one and five years ago results to identify significant changes between pre- and during-COVID home relocaiton. 

## 4.1 Moved address
Table 10 and Figure 1 compare the rates of living in the same address as one year ago  for the inner region between the 2016 and 2021 censuses.  

```{r chi_square_inner_change_1_yr, fig.fullwidth=FALSE, fig.margin = FALSE, fig.cap= "Figure 1: change residential location from one year prior to the census", fig.height=4, warning=FALSE, echo=FALSE, message = FALSE, show_col_types = FALSE} 


#First extra Inner Regions from 2016 and 2021 tables and combine into a single contingency table
#but first they all need to have the same column names
colnames(X2016_combined_1yr_ago)[2] <- "Same address"
colnames(X2021_combined_1yr_ago)[2] <- "Same address"
colnames(X2016_combined_1yr_ago)[16] <- "Overseas"
colnames(X2016_combined_1yr_ago)[16] <- "Overseas"
names(X2016_combined_1yr_ago) <- names(X2021_combined_1yr_ago)
#combined table
inner_2016_2021_1yr_ago <- rbind(X2016_combined_1yr_ago[1,], X2021_combined_1yr_ago[1,])
#change first column so that it shows the correct descriptions
inner_2016_2021_1yr_ago[,1] <- c("2016", "2021") 
colnames(inner_2016_2021_1yr_ago)[1] <- "Census"

library(gplots)
library(ggpubr)
#dt <- as.table(as.matrix(inner_2016_2021_1yr_ago))
#balloonplot(t(dt), xlab = "", ylab="", label = FALSE, show.margins = FALSE)
#mosaicplot(as.tibble(inner_2016_2021_1yr_ago), shade = TRUE, las = 2)

#NEXT USE GGBARSTATS and DATA ORGANISED BY COUNTS (see https://indrajeetpatil.github.io/ggstatsplot/articles/web_only/ggbarstats.html) 
to do the 2-way contingency statistical tests. 7

```
